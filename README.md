<h1>Causal Experiment</h1><br>
Team members :  Ying Zhang, Christian Lawrence, Jiazheng Li, Michelle Lensing, and Tiam Moradi<br><br>


<h2>Causal_Experiment_Remote_Exam</h2> <br><br>
With remote learning becoming the norm across universities in the United States, teachers have had to innovate around the way they assess their students. Some universities and professors have adopted strict remote exam guidelines while others have taken advantage of the flexible situation and provided more relaxed guidelines, which begs the question(s): what’s the best way to distribute a remote assessment? Does having a quiz with camera on affect a student’s performance? Will having people sit on a call improve or worsen student scores? This experiment aims to take a first pass at assessing the optimal method of administering remote assessments. <br><br>


<h2>Hypothesis</h2>
Our team is split on whether the treatment or control would lead to better outcomes (higher scores and less
time taken). One on hand, removing time constraints and the need for cameras may relieve pressure and
allow students to perform better. On the other, students may take tests more seriously with the presence of a
remote proctor and their cameras on. We also suspect that certain participant characteristics might affect
the treatment effects. For example, English native speakers might score better than those who are not.<br><br>


<h2>Experiment Design</h2>

To conduct appropriate blocking randomization, we first gave the participants a survey to uncover demographic
information. This information will be used for either blocking randomization or as covariates in our analysis.
Additionally, we included a question around which time/date they preferred to take the assessment, providing
four options across three days; their responses were used for scheduling purposes.<br><br>
Treatment (N=61, treatment group = 32, control group = 29)<br>
Control : Take assessment unproctored<br>
Treatment : Take proctored assessment on a Zoom call with a camera on<br><br>

Assessment and Delivery Method<br>
The assessment consisted of 21 logic reasoning questions, which involved some math and some reading
comprehension.<br>
Participants on the Zoom call were given the assessment when they signed on to ensure everyone started the
assessment at the same time. We did not provide a time limit for the assessment, so participants could take
as long as they wanted; however, we did inform them that it takes an average of 10-15 minutes to complete.
The assessment was administered through Qualtrics. We modified the original questions and used images
(instead of text) to display quiz questions on the Qualtrics platform to prevent participants from googling
1
answers. We also required participants to refrain from searching for the answers online or collaborating with
other people during the assessment, simulating a closed book testing environment.<br>
We scheduled participants to take the assessment on the time/date they selected on the preliminary survey,
either sending them a Zoom link 5-10 minutes before their scheduled time and the assessment link during the
call if they were in the treatment group, or sending them the assessment link at their scheduled time if they
were in the control group.<br>
Both groups received email reminders prior to the assessment, indicating whether they will be taking the
assessment on Zoom or not. They were unaware of the existence of the alternative group (e.g. if they took
the assessment proctored on Zoom, they were not informed of the unproctored group).<br><br>

<h2>Outcomes</h2>
Our primary outcome measure will be how well the participants scored in the exam (i.e. how many questions
they answered correctly). The second will be the time taken to complete the assessment. Although not our
main outcome, we also did look into number of clicks as an outcome for an analysis.
